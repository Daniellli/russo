{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import os.path as osp\n",
    "os.chdir(osp.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-14 22:24:58.673 | INFO     | __main__:get_refer_it_3D:32 - len of sr3d_test : 17726\n",
      "2022-10-14 22:24:58.674 | INFO     | __main__:get_refer_it_3D:34 -  column of sr3d_test : Index(['scan_id', 'target_id', 'distractor_ids', 'utterance', 'stimulus_id',\n",
      "       'coarse_reference_type', 'reference_type', 'instance_type',\n",
      "       'anchors_types', 'anchor_ids', 'tokens', 'dataset',\n",
      "       'mentions_target_class', 'correct_guess', 'is_train'],\n",
      "      dtype='object')\n",
      "2022-10-14 22:24:58.676 | INFO     | __main__:get_refer_it_3D:35 - scene number : 255\n",
      "2022-10-14 22:24:58.679 | INFO     | __main__:get_refer_it_3D:45 - min sample: 4 \n",
      " max sample : 682 \n",
      " avg sample: 69.51372549019608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan_id                                                       scene0629_00\n",
      "target_id                                                                0\n",
      "distractor_ids                                                         [2]\n",
      "utterance                              the door that is near the end table\n",
      "stimulus_id                                        scene0629_00-door-2-0-2\n",
      "coarse_reference_type                                           horizontal\n",
      "reference_type                                                     closest\n",
      "instance_type                                                         door\n",
      "anchors_types                                                ['end table']\n",
      "anchor_ids                                                             [7]\n",
      "tokens                   ['the', 'door', 'that', 'is', 'near', 'the', '...\n",
      "dataset                                                               sr3d\n",
      "mentions_target_class                                                 True\n",
      "correct_guess                                                         True\n",
      "is_train                                                             False\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd \n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from loguru import logger\n",
    "'''\n",
    "description:  获取SR3D 作者划分好的 训练集 和测试集\n",
    "param {*} split\n",
    "return {*}\n",
    "'''\n",
    "def get_split_list(dataset_name=\"sr3d\" ,split='train'):\n",
    "    with open('data/meta_data/%s_%s_scans.txt' % (dataset_name,split)) as f:\n",
    "        scan_ids = set(eval(f.read()))\n",
    "    logger.info(f\" len of {dataset_name,split} : {len(scan_ids)}\")\n",
    "    return scan_ids\n",
    "\n",
    "\n",
    "def get_ratio_split_list(ratio,dataset_name=\"sr3d\" ,split='train'):\n",
    "    with open('data/meta_data/%s_%s_%.1f.txt' % (dataset_name,split,ratio)) as f:\n",
    "        scan_ids = f.read().split(\"\\n\")\n",
    "    logger.info(f\" len of {dataset_name,split,ratio} : {len(scan_ids)}\")\n",
    "    return scan_ids\n",
    "\n",
    "\n",
    "def read_txt(file_name):\n",
    "    with open(file_name,'r') as f:\n",
    "        scan_ids = f.read().split(\"\\n\")\n",
    "    logger.info(f\" len of {file_name} : {len(scan_ids)}\")\n",
    "    return scan_ids\n",
    "\n",
    "\n",
    "'''\n",
    "description:  从SR3D作者那获取 详细的标注数据\n",
    "param {*} split_name\n",
    "return {*}\n",
    "'''\n",
    "def get_refer_it_3D(split_name='sr3d'):\n",
    "    scanrefer_root=\"datasets/refer_it_3d\"\n",
    "    data = pd.read_csv(osp.join(scanrefer_root,split_name+\".csv\"))\n",
    "    \n",
    "    # logger.info(f\"len of {split_name} : {data.shape[0]}\")\n",
    "    all_attrs = data.columns\n",
    "    # logger.info(f\" column of {split_name} : {all_attrs}\")\n",
    "    # logger.info(f\"scene number : {len(set(data['scan_id']))}\")\n",
    "\n",
    "    stat = Counter(data['scan_id'])\n",
    "\n",
    "    scane_stat = np.array([v for k ,v in stat.items()])\n",
    "    avg_sample =scane_stat.mean()\n",
    "    min_sample =scane_stat.min()\n",
    "    max_sample =scane_stat.max()\n",
    "\n",
    "\n",
    "    # logger.info(f\"min sample: {min_sample} \\n max sample : {max_sample} \\n avg sample: {avg_sample}\")    \n",
    "    # print(data.iloc[0,:])\n",
    "    return data\n",
    "    \n",
    "      \n",
    "\n",
    "\n",
    "\n",
    "def generate_NR3D_labeled_scene_txt(labeled_ratio):\n",
    "    nr3d_ids = get_split_list(dataset_name='nr3d')\n",
    "\n",
    "    num_scans = len(nr3d_ids)\n",
    "    num_labeled_scans = int(num_scans*labeled_ratio)\n",
    "\n",
    "\n",
    "    choices = np.random.choice(num_scans, num_labeled_scans, replace=False)#* 从num_scans 挑选num_labeled_scans 个场景 出来 \n",
    "\n",
    "    labeled_scan_names = list(np.array(list(nr3d_ids))[choices])\n",
    "    \n",
    "    with open(os.path.join('data/meta_data/nr3d_train_{}.txt'.format(labeled_ratio)), 'w') as f:\n",
    "        f.write('\\n'.join(labeled_scan_names))\n",
    "    \n",
    "    logger.info('\\tSelected {} labeled scans, remained {} unlabeled scans'.format(len(labeled_scan_names),num_scans- len(labeled_scan_names)))\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "# sr3d_ids = get_split_list()\n",
    "# sr3d_ids_test = get_split_list(split = 'test')\n",
    "# nr3d_ids = get_split_list(dataset_name='nr3d')\n",
    "# nr3d_ids_test = get_split_list(dataset_name='nr3d',split = 'test')\n",
    "\n",
    "\n",
    "\n",
    "# get_refer_it_3D('sr3d+')\n",
    "# get_refer_it_3D('sr3d')\n",
    "# get_refer_it_3D('sr3d_test')\n",
    "# get_refer_it_3D('sr3d_train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'datasets/scanrefer/ScanRefer_filtered_test.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_793872/3067256072.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# a = get_scanrefer(split='val')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_scanrefer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_scanrefer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m# get_scanrefer()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_793872/3067256072.py\u001b[0m in \u001b[0;36mget_scanrefer\u001b[0;34m(split)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"datasets/scanrefer/ScanRefer_filtered.json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datasets/scanrefer/ScanRefer_filtered_test.json'"
     ]
    }
   ],
   "source": [
    "\n",
    "def statstic_nr3d():\n",
    "    nr3d = get_refer_it_3D('nr3d')\n",
    "    nr3d_train =  get_split_list(dataset_name='nr3d')\n",
    "    len_test= len_train= 0\n",
    "    for idx in range(nr3d.shape[0]):\n",
    "        if nr3d.iloc[idx,:]['scan_id'] in nr3d_train:\n",
    "            len_train+=1\n",
    "        else:\n",
    "            len_test+=1\n",
    "    print(f\"len of train : {len_train}, len of test : {len_test}\")\n",
    "\n",
    "\n",
    "\n",
    "def statstic_nr3d_by_ratio(ratio,datasets='nr3d'):\n",
    "    \n",
    "    nr3d = get_refer_it_3D(datasets)\n",
    "    nr3d_ratio=  get_ratio_split_list(ratio,dataset_name=datasets)\n",
    "    \n",
    "    num = 0 \n",
    "    for idx in range(nr3d.shape[0]):\n",
    "        if nr3d.iloc[idx,:]['scan_id'] in nr3d_ratio:\n",
    "            num+=1\n",
    "        \n",
    "    print(f\"len of {datasets,ratio} : {num}\")\n",
    "\n",
    "\n",
    "# datasets = 'sr3d'\n",
    "# for n in np.linspace(0.1,0.9,9):\n",
    "#     # print(round(n,1))\n",
    "#     statstic_nr3d_by_ratio(round(n,1),datasets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in np.linspace(0.1,0.9,9):\n",
    "#     generate_NR3D_labeled_scene_txt(round(x,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-14 23:30:07.210 | INFO     | __main__:read_txt:30 -  len of datasets/scanrefer/ScanRefer_filtered_train_0.1.txt : 56\n",
      "2022-10-14 23:30:07.451 | INFO     | __main__:read_txt:30 -  len of datasets/scanrefer/ScanRefer_filtered_train_0.2.txt : 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of scanrefer 0.1 : 3843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-14 23:30:07.698 | INFO     | __main__:read_txt:30 -  len of datasets/scanrefer/ScanRefer_filtered_train_0.3.txt : 168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of scanrefer 0.2 : 7191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-14 23:30:07.972 | INFO     | __main__:read_txt:30 -  len of datasets/scanrefer/ScanRefer_filtered_train_0.4.txt : 224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of scanrefer 0.3 : 10819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-14 23:30:08.199 | INFO     | __main__:read_txt:30 -  len of datasets/scanrefer/ScanRefer_filtered_train_0.5.txt : 281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of scanrefer 0.4 : 14467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-14 23:30:08.481 | INFO     | __main__:read_txt:30 -  len of datasets/scanrefer/ScanRefer_filtered_train_0.6.txt : 337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of scanrefer 0.5 : 18866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-14 23:30:08.778 | INFO     | __main__:read_txt:30 -  len of datasets/scanrefer/ScanRefer_filtered_train_0.7.txt : 393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of scanrefer 0.6 : 21859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-14 23:30:09.091 | INFO     | __main__:read_txt:30 -  len of datasets/scanrefer/ScanRefer_filtered_train_0.8.txt : 449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of scanrefer 0.7 : 25478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-14 23:30:09.416 | INFO     | __main__:read_txt:30 -  len of datasets/scanrefer/ScanRefer_filtered_train_0.9.txt : 505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of scanrefer 0.8 : 29263\n",
      "len of scanrefer 0.9 : 32832\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_scanrefer(split=None):\n",
    "    if split is not None :\n",
    "        path = \"datasets/scanrefer/ScanRefer_filtered_%s.json\"%split\n",
    "    else :\n",
    "        path = \"datasets/scanrefer/ScanRefer_filtered.json\"\n",
    "\n",
    "    with open (path,'r')as f :\n",
    "        data =json.load(f)\n",
    "    \n",
    "    length = len(data)\n",
    "    # logger.info(f\" len of {split} split : {length}\")\n",
    "    # all_scene = set([x['scene_id']  for x in data])\n",
    "    # logger.info(f\" scene number  of {split} split : {len(all_scene)}\")\n",
    "\n",
    "    # all_object_id = set([x['object_id']  for x in data])\n",
    "    # logger.info(f\" object number  of {split} split : {len(all_object_id)}\")\n",
    "\n",
    "    # all_anno_id = set([x['ann_id']  for x in data])\n",
    "    # logger.info(f\" anno number  of {split} split : {len(all_anno_id)}\")\n",
    "\n",
    "    # print(data[0])\n",
    "    \n",
    "    return data\n",
    "\n",
    "def get_ratio_scanrefer(ratio,split=None):\n",
    "    \n",
    "    path = \"datasets/scanrefer/ScanRefer_filtered_train_%.1f.txt\"%(ratio)\n",
    "\n",
    "    scanrefer = get_scanrefer(split='train')\n",
    "    scan_ids = read_txt(path)\n",
    "\n",
    "    \n",
    "    num = 0 \n",
    "    for refer in scanrefer:\n",
    "        if refer['scene_id'] in scan_ids:\n",
    "            num+=1\n",
    "    \n",
    "    print(f\"len of scanrefer {ratio} : {num}\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def generate_scanrefer_labeled_scene_txt(labeled_ratio):\n",
    "    all_scenes = get_scanrefer(split='train')\n",
    "\n",
    "    num_scans = len(all_scenes)\n",
    "    num_labeled_scans = int(num_scans*labeled_ratio)\n",
    "\n",
    "\n",
    "    choices = np.random.choice(num_scans, num_labeled_scans, replace=False)#* 从num_scans 挑选num_labeled_scans 个场景 出来 \n",
    "\n",
    "    labeled_scan_names = list(np.array(list(all_scenes))[choices])\n",
    "    \n",
    "    with open(os.path.join('datasets/scanrefer/ScanRefer_filtered_train_{}.txt'.format(labeled_ratio)), 'w') as f:\n",
    "        f.write('\\n'.join(labeled_scan_names))\n",
    "    \n",
    "    logger.info('\\tSelected {} labeled scans, remained {} unlabeled scans'.format(len(labeled_scan_names),num_scans- len(labeled_scan_names)))\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "# get_scanrefer(split='val')\n",
    "# get_scanrefer(split='test')\n",
    "# get_scanrefer()\n",
    "# scanrefer = get_scanrefer(split='train')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for n in np.linspace(0.1,0.9,9):\n",
    "    # print(round(n,1))\n",
    "    get_ratio_scanrefer(round(n,1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for x in np.linspace(0.1,0.9,9):\n",
    "#     generate_scanrefer_labeled_scene_txt(round(x,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-14 23:24:24.080 | INFO     | __main__:get_scanrefer:11 -  len of train split : 36665\n",
      "2022-10-14 23:24:24.094 | INFO     | __main__:get_scanrefer:13 -  scene number  of train split : 562\n",
      "2022-10-14 23:24:24.103 | INFO     | __main__:get_scanrefer:16 -  object number  of train split : 87\n",
      "2022-10-14 23:24:24.106 | INFO     | __main__:get_scanrefer:19 -  anno number  of train split : 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scene_id': 'scene0000_00', 'object_id': '39', 'object_name': 'cabinet', 'ann_id': '1', 'description': 'a white cabinet in the corner of the room. in the direction from the door and from the inside . it will be on the left, there is a small brown table on the left side of the cabinet and a smaller table on the right side of the cabinet', 'token': ['a', 'white', 'cabinet', 'in', 'the', 'corner', 'of', 'the', 'room', '.', 'in', 'the', 'direction', 'from', 'the', 'door', 'and', 'from', 'the', 'inside', '.', 'it', 'will', 'be', 'on', 'the', 'left', ',', 'there', 'is', 'a', 'small', 'brown', 'table', 'on', 'the', 'left', 'side', 'of', 'the', 'cabinet', 'and', 'a', 'smaller', 'table', 'on', 'the', 'right', 'side', 'of', 'the', 'cabinet']}\n"
     ]
    }
   ],
   "source": [
    "scanrefer = get_scanrefer(split='train')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('cerberus2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6c611ea97879ac7a66cc839a92507d3b630293601f06de205ed521c4e63823d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
