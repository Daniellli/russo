{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import os.path as osp\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "\n",
    "os.chdir(osp.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "description:  获取SR3D 作者划分好的 训练集 和测试集\n",
    "param {*} split\n",
    "return {*}\n",
    "'''\n",
    "def get_split_list(dataset_name=\"sr3d\" ,split='train'):\n",
    "    with open('data/meta_data/%s_%s_scans.txt' % (dataset_name,split)) as f:\n",
    "        scan_ids = set(eval(f.read()))\n",
    "    logger.info(f\" len of {dataset_name,split} : {len(scan_ids)}\")\n",
    "    return scan_ids\n",
    "\n",
    "\n",
    "def get_ratio_split_list(ratio,dataset_name=\"sr3d\" ,split='train'):\n",
    "    with open('data/meta_data/%s_%s_%.1f.txt' % (dataset_name,split,ratio)) as f:\n",
    "        scan_ids = f.read().split(\"\\n\")\n",
    "    logger.info(f\" len of {dataset_name,split,ratio} : {len(scan_ids)}\")\n",
    "    return scan_ids\n",
    "\n",
    "\n",
    "def read_txt(file_name):\n",
    "    with open(file_name,'r') as f:\n",
    "        scan_ids = f.read().split(\"\\n\")\n",
    "    logger.info(f\" len of {file_name} : {len(scan_ids)}\")\n",
    "    return scan_ids\n",
    "\n",
    "\n",
    "'''\n",
    "description:  从SR3D作者那获取 详细的标注数据\n",
    "param {*} split_name\n",
    "return {*}\n",
    "'''\n",
    "def get_refer_it_3D(split_name='sr3d'):\n",
    "    scanrefer_root=\"datasets/refer_it_3d\"\n",
    "    data = pd.read_csv(osp.join(scanrefer_root,split_name+\".csv\"))\n",
    "    \n",
    "    # logger.info(f\"len of {split_name} : {data.shape[0]}\")\n",
    "    all_attrs = data.columns\n",
    "    # logger.info(f\" column of {split_name} : {all_attrs}\")\n",
    "    # logger.info(f\"scene number : {len(set(data['scan_id']))}\")\n",
    "\n",
    "    stat = Counter(data['scan_id'])\n",
    "\n",
    "    scane_stat = np.array([v for k ,v in stat.items()])\n",
    "    avg_sample =scane_stat.mean()\n",
    "    min_sample =scane_stat.min()\n",
    "    max_sample =scane_stat.max()\n",
    "\n",
    "\n",
    "    # logger.info(f\"min sample: {min_sample} \\n max sample : {max_sample} \\n avg sample: {avg_sample}\")    \n",
    "    # print(data.iloc[0,:])\n",
    "    return data\n",
    "    \n",
    "      \n",
    "\n",
    "def save_txt(path,data):\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(data)\n",
    "    \n",
    "\n",
    "'''\n",
    "description:  \n",
    "param {*} labeled_ratio\n",
    "return {*}\n",
    "'''\n",
    "def generate_NR3D_labeled_scene_txt(labeled_ratio):\n",
    "    nr3d_ids = get_split_list(dataset_name='nr3d')\n",
    "\n",
    "    num_scans = len(nr3d_ids)\n",
    "    num_labeled_scans = int(num_scans*labeled_ratio)\n",
    "\n",
    "\n",
    "    choices = np.random.choice(num_scans, num_labeled_scans, replace=False)#* 从num_scans 挑选num_labeled_scans 个场景 出来 \n",
    "\n",
    "    labeled_scan_names = list(np.array(list(nr3d_ids))[choices])\n",
    "    \n",
    "    save_txt(os.path.join('data/meta_data/nr3d_train_{}.txt'.format(labeled_ratio)),'\\n'.join(labeled_scan_names))\n",
    "   \n",
    "    logger.info('\\tSelected {} labeled scans, remained {} unlabeled scans'.format(len(labeled_scan_names),num_scans- len(labeled_scan_names)))\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "# sr3d_ids = get_split_list()\n",
    "# sr3d_ids_test = get_split_list(split = 'test')\n",
    "# nr3d_ids = get_split_list(dataset_name='nr3d')\n",
    "# nr3d_ids_test = get_split_list(dataset_name='nr3d',split = 'test')\n",
    "\n",
    "# get_refer_it_3D('sr3d+')\n",
    "# get_refer_it_3D('sr3d')\n",
    "# get_refer_it_3D('sr3d_test')\n",
    "# get_refer_it_3D('sr3d_train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "description:  统计NR3D 数据集\n",
    "return {*}\n",
    "'''\n",
    "def statstic_nr3d():\n",
    "    nr3d = get_refer_it_3D('nr3d')\n",
    "    nr3d_train =  get_split_list(dataset_name='nr3d')\n",
    "    len_test= len_train= 0\n",
    "    for idx in range(nr3d.shape[0]):\n",
    "        if nr3d.iloc[idx,:]['scan_id'] in nr3d_train:\n",
    "            len_train+=1\n",
    "        else:\n",
    "            len_test+=1\n",
    "    print(f\"len of train : {len_train}, len of test : {len_test}\")\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "description:  根据比例统计每个子集\n",
    "param {*} ratio\n",
    "param {*} datasets\n",
    "return {*}\n",
    "'''\n",
    "def statstic_nr3d_by_ratio(ratio,datasets='nr3d'):\n",
    "    \n",
    "    nr3d = get_refer_it_3D(datasets)\n",
    "    nr3d_ratio=  get_ratio_split_list(ratio,dataset_name=datasets)\n",
    "    \n",
    "    num = 0 \n",
    "    for idx in range(nr3d.shape[0]):\n",
    "        if nr3d.iloc[idx,:]['scan_id'] in nr3d_ratio:\n",
    "            num+=1\n",
    "        \n",
    "    print(f\"len of {datasets,ratio} : {num}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_scene_data(all_data,scene = 'scene0525_00'):\n",
    "    \n",
    "\n",
    "    return_data = [] \n",
    "    for  idx in range(all_data.shape[0]):\n",
    "\n",
    "        if all_data.iloc[idx]['scan_id'] == scene:\n",
    "            return_data.append(all_data.iloc[idx])\n",
    "            \n",
    "\n",
    "    return return_data\n",
    "\n",
    "\n",
    "def get_assignment_id(all_data,scene_list):\n",
    "    assignments = []\n",
    "    for idx in range(all_data.shape[0]):\n",
    "        if all_data.iloc[idx]['scan_id'] in scene_list: \n",
    "            assignments.append (all_data.iloc[idx]['assignmentid'])\n",
    "        \n",
    "    return assignments\n",
    "\n",
    "# scene_0525  = get_scene_data(nr3d)\n",
    "# all_assign_ids = get_assignment_id(nr3d)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-17 12:09:31.995 | INFO     | __main__:get_split_list:9 -  len of ('nr3d', 'train') : 511\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def split_labeled_according_assignment_id(assign_ids , ratio=0.4):\n",
    "    \n",
    "    \n",
    "    length = len(assign_ids)\n",
    "    choices = np.random.choice(length,int(length*ratio))\n",
    "\n",
    "    return np.array(assign_ids)[choices]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nr3d = get_refer_it_3D('nr3d')\n",
    "train_split = get_split_list(dataset_name='nr3d')\n",
    "\n",
    "nr3d_all_assign_ids = get_assignment_id(nr3d,train_split)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# for ratio in np.linspace(0.1,0.9,9):\n",
    "#     ratio = round(ratio,1)\n",
    "#     split_labeled_data = split_labeled_according_assignment_id(nr3d_all_assign_ids,ratio)\n",
    "#     print(f\"length  = {len(split_labeled_data)}\")\n",
    "#     save_txt(os.path.join('data/meta_data/nr3d_train_{}.txt'.format(ratio)),'\\n'.join(split_labeled_data.astype(np.str0).tolist()))\n",
    "\n",
    "\n",
    "\n",
    "save_txt(os.path.join('data/meta_data/nr3d_train_all_assignmentid.txt'),'\\n'.join(np.array(nr3d_all_assign_ids).astype(np.str0).tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-17 12:04:49.376 | INFO     | __main__:read_txt:23 -  len of data/meta_data/nr3d_train_0.2.txt : 6583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5498\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = read_txt('data/meta_data/nr3d_train_{}.txt'.format(0.2))\n",
    "\n",
    "\n",
    "\n",
    "sum_=0\n",
    "for idx in range(nr3d.shape[0]):\n",
    "    \n",
    "    # if str(nr3d.iloc[idx]['assignmentid']) in data and nr3d.iloc[idx]['mentions_target_class']  and nr3d.iloc[idx]['correct_guess'] :\n",
    "    if str(nr3d.iloc[idx]['assignmentid']) in data and nr3d.iloc[idx]['mentions_target_class']:\n",
    "        sum_+=1\n",
    "    \n",
    "\n",
    "\n",
    "print(sum_)\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_scanrefer(split=None):\n",
    "    if split is not None :\n",
    "        path = \"datasets/scanrefer/ScanRefer_filtered_%s.json\"%split\n",
    "    else :\n",
    "        path = \"datasets/scanrefer/ScanRefer_filtered.json\"\n",
    "\n",
    "    with open (path,'r')as f :\n",
    "        data =json.load(f)\n",
    "    \n",
    "    length = len(data)\n",
    "    # logger.info(f\" len of {split} split : {length}\")\n",
    "    # all_scene = set([x['scene_id']  for x in data])\n",
    "    # logger.info(f\" scene number  of {split} split : {len(all_scene)}\")\n",
    "\n",
    "    # all_object_id = set([x['object_id']  for x in data])\n",
    "    # logger.info(f\" object number  of {split} split : {len(all_object_id)}\")\n",
    "\n",
    "    # all_anno_id = set([x['ann_id']  for x in data])\n",
    "    # logger.info(f\" anno number  of {split} split : {len(all_anno_id)}\")\n",
    "\n",
    "    # print(data[0])\n",
    "    \n",
    "    return data\n",
    "\n",
    "def get_ratio_scanrefer(ratio,split=None):\n",
    "    \n",
    "    path = \"datasets/scanrefer/ScanRefer_filtered_train_%.1f.txt\"%(ratio)\n",
    "\n",
    "    scanrefer = get_scanrefer(split='train')\n",
    "    scan_ids = read_txt(path)\n",
    "\n",
    "    \n",
    "    num = 0 \n",
    "    for refer in scanrefer:\n",
    "        if refer['scene_id'] in scan_ids:\n",
    "            num+=1\n",
    "    \n",
    "    print(f\"len of scanrefer {ratio} : {num}\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "description: \n",
    "param {*} labeled_ratio\n",
    "return {*}\n",
    "'''\n",
    "def generate_scanrefer_labeled_scene_txt(labeled_ratio):\n",
    "    all_scenes = get_scanrefer(split='train')\n",
    "\n",
    "    num_scans = len(all_scenes)\n",
    "    num_labeled_scans = int(num_scans*labeled_ratio)\n",
    "\n",
    "\n",
    "    choices = np.random.choice(num_scans, num_labeled_scans, replace=False)#* 从num_scans 挑选num_labeled_scans 个场景 出来 \n",
    "\n",
    "    labeled_scan_names = list(np.array(list(all_scenes))[choices])\n",
    "    \n",
    "    with open(os.path.join('datasets/scanrefer/ScanRefer_filtered_train_{}.txt'.format(labeled_ratio)), 'w') as f:\n",
    "        f.write('\\n'.join(labeled_scan_names))\n",
    "    \n",
    "    logger.info('\\tSelected {} labeled scans, remained {} unlabeled scans'.format(len(labeled_scan_names),num_scans- len(labeled_scan_names)))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "'''\n",
    "description:  一次性生成所有比例的数据集划分\n",
    "return {*}\n",
    "'''\n",
    "def generate_ratio_labeled_datasets():\n",
    "    for x in np.linspace(0.1,0.9,9):\n",
    "        generate_NR3D_labeled_scene_txt(round(x,1))\n",
    "    for x in np.linspace(0.1,0.9,9):\n",
    "        generate_scanrefer_labeled_scene_txt(round(x,1))\n",
    "\n",
    "'''\n",
    "description:  tmp code for stat \n",
    "return {*}\n",
    "'''\n",
    "def stat():\n",
    "    datasets = ['sr3d','nr3d']\n",
    "\n",
    "    for dataset in datasets:\n",
    "        for n in np.linspace(0.1,0.9,9):\n",
    "            # print(round(n,1))\n",
    "            statstic_nr3d_by_ratio(round(n,1),dataset)\n",
    "            \n",
    "    for n in np.linspace(0.1,0.9,9):\n",
    "        get_ratio_scanrefer(round(n,1))\n",
    "        \n",
    "\n",
    "\n",
    "# get_scanrefer(split='val')\n",
    "# get_scanrefer(split='test')\n",
    "# get_scanrefer()\n",
    "# scanrefer = get_scanrefer(split='train')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('cerberus2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c7eafccb8f457aa8ce756ee28bedbf2f0acb240aef93477faad38317e939d03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
